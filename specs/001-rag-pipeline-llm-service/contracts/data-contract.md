# Data Contract: HR Data Pipeline ↔ RAG LLM Service

**Date**: 2026-01-21  
**Version**: 1.0  
**Status**: Approved  
**Parties**: 
- **Producer**: HR Data Pipeline team (Feature: `1-hr-data-pipeline`)
- **Consumer**: RAG LLM Service team (Feature: `001-rag-pipeline-llm-service`)

---

## Executive Summary

This data contract formalizes the interface between the HR Data Pipeline (which ingests and processes documents) and the RAG LLM Service (which retrieves and generates answers). Both teams must adhere to this contract to ensure seamless integration.

---

## Embedding Model Agreement

**❌ DO NOT VARY** - Both teams must use identical embedding model:

| Property | Value |
|----------|-------|
| **Model Name** | `all-MiniLM-L6-v2` |
| **Dimensions** | 384 |
| **Provider** | sentence-transformers |
| **Version** | 2.2.2+ |
| **Similarity Metric** | Cosine distance |

**Rationale**:
- Lightweight enough to run on CPU (384 vs 768+ dimensions)
- Sufficient semantic quality for HR policy questions
- Widely documented and stable
- Aligns with HR pipeline FR-009 choice

**Breaking Changes**: Any change to embedding model requires:
1. Both teams coordinate timing
2. Rebuild entire vector database
3. Update version number in this contract
4. Test cross-compatibility before deployment

---

## Vector Database Schema

### Collection Name
- **Name**: `corporate_documents`
- **Purpose**: Single collection storing all ingested documents (PDF + Kaggle + HuggingFace sources)
- **Immutable**: Yes (do not rename or recreate without coordinating)

### Chunk Document Format

Every chunk stored in ChromaDB MUST follow this exact format:

```python
{
    "id": "chunk_{source_type}_{doc_hash}_{index}",
    # Example: "chunk_pdf_a1b2c3_0", "chunk_kaggle_x9y8z7_5"
    
    "embedding": [0.023, -0.145, ...],  # 384 dimensions
    
    "metadatas": {
        # REQUIRED fields (set by HR Pipeline)
        "source_doc": "hr_policy.pdf",           # Original document filename
        "source_type": "pdf",                    # Value: "pdf" | "kaggle" | "huggingface"
        "page_number": 5,                        # Integer (page in source document)
        "section_title": "Vacation Policy",      # Section heading or context
        "chunk_index": 0,                        # Position within document (0-based)
        
        # RECOMMENDED fields (set by HR Pipeline, used by RAG for context)
        "related_topic": "Vacation",             # HR topic category
        "timestamp": "2026-01-21T14:00:00Z",    # ISO 8601 ingestion time
        
        # VALIDATION fields (set by HR Pipeline)
        "contradiction_check": true,             # Boolean: passed validation
        "duplicate_check": true,                 # Boolean: passed validation
        "embedding_model": "all-MiniLM-L6-v2"   # Confirm model version
    },
    
    "document": "All personnel are entitled to 20 days of paid leave annually..."
}
```

### Field Definitions

| Field | Type | Required | Set By | Used By | Notes |
|-------|------|----------|--------|---------|-------|
| `id` | string | ✅ | HR Pipeline | ChromaDB | Unique chunk identifier |
| `embedding` | array[float] | ✅ | HR Pipeline | RAG (retrieval) | Must be 384 dimensions |
| `source_doc` | string | ✅ | HR Pipeline | RAG (citations) | Filename only, no path |
| `source_type` | string | ✅ | HR Pipeline | RAG (filtering) | "pdf" \| "kaggle" \| "huggingface" |
| `page_number` | integer | ✅ | HR Pipeline | RAG (citations) | 1-based page index (or null if N/A) |
| `section_title` | string | ✅ | HR Pipeline | RAG (context) | Section heading from source |
| `chunk_index` | integer | ✅ | HR Pipeline | RAG (sequencing) | 0-based position in document |
| `related_topic` | string | ⚠️ | HR Pipeline | RAG (optional) | HR topic for categorization |
| `timestamp` | string | ⚠️ | HR Pipeline | RAG (audit) | ISO 8601 format |
| `contradiction_check` | boolean | ✅ | HR Pipeline | RAG (validation) | Always true (failed checks excluded) |
| `duplicate_check` | boolean | ✅ | HR Pipeline | RAG (validation) | Always true (duplicates excluded) |
| `embedding_model` | string | ✅ | HR Pipeline | RAG (verification) | Must equal "all-MiniLM-L6-v2" |
| `document` | string | ✅ | HR Pipeline | RAG (context) | Chunk text content |

---

## Retrieval Query Format

### HR Pipeline → RAG Service (ChromaDB API Call)

When RAG service queries ChromaDB, it MUST use:

```python
# Generated by RAG service
query_vector = embed(user_question, model="all-MiniLM-L6-v2")  # 384-dim

# ChromaDB query
results = chromadb.collection("corporate_documents").query(
    query_embeddings=[query_vector],
    n_results=5,
    where={
        # Optional filtering by source type
        "source_type": {"$in": ["pdf", "kaggle"]}  # Filter to primary sources
    },
    include=["documents", "embeddings", "metadatas", "distances"]
)
```

### Expected Response Structure

```python
{
    "ids": [["chunk_pdf_hash_0", "chunk_kaggle_hash_3", ...]],
    
    "documents": [["Vacation policy text here...", "External HR guidance...", ...]],
    
    "embeddings": [
        [0.123, -0.456, ...],  # 384 dimensions
        [0.234, -0.567, ...],  # 384 dimensions
        ...
    ],
    
    "metadatas": [[
        {
            "source_doc": "hr_policy.pdf",
            "source_type": "pdf",
            "page_number": 5,
            "section_title": "Vacation Policy",
            "chunk_index": 0,
            "contradiction_check": true,
            "duplicate_check": true,
            "embedding_model": "all-MiniLM-L6-v2"
        },
        {...}
    ]],
    
    "distances": [[0.234, 0.445, 0.567, ...]],  # Cosine distance
    
    "uris": null  # ChromaDB may include this
}
```

---

## Similarity Score Interpretation

### Confidence Calculation

RAG service MUST calculate confidence from retrieved chunks:

```python
# Average distance (cosine) from top-k retrieved chunks
avg_distance = mean([0.234, 0.445, 0.567])  # Example: 0.415

# Convert distance to similarity (0 = identical, 1 = orthogonal)
similarity = 1.0 - avg_distance  # Result: 0.585

# Confidence score
confidence = similarity  # Use directly as confidence [0.0-1.0]

# Decision logic
if confidence >= 0.5:
    return generated_answer with citations
else:
    return "I don't know" response
```

### Thresholds

| Metric | Value | Set By | Notes |
|--------|-------|--------|-------|
| **Retrieval Relevance** | >0.75 | HR Pipeline (FR-005) | Threshold for external data sourcing |
| **Duplicate Detection** | >0.85 | HR Pipeline (FR-007) | Similarity threshold for duplicates |
| **Answer Confidence** | ≥0.5 | RAG Service (FR-020) | Minimum confidence to return answer |
| **Borderline Flag** | 0.45-0.55 | RAG Service | Log for manual review |

---

## Metadata Serialization

### JSON Format (for REST API transmission)

When RAG service calls ChromaDB via REST API, metadata is returned as:

```json
{
    "metadatas": [
        {
            "source_doc": "hr_policy.pdf",
            "source_type": "pdf",
            "page_number": 5,
            "section_title": "Vacation Policy",
            "chunk_index": 0,
            "related_topic": "Vacation",
            "timestamp": "2026-01-21T14:00:00Z",
            "contradiction_check": true,
            "duplicate_check": true,
            "embedding_model": "all-MiniLM-L6-v2"
        }
    ]
}
```

### Null Values

```python
# Allowed null values (HR Pipeline may omit these):
{
    "page_number": null,           # If document has no pages (e.g., web article)
    "related_topic": null,         # If topic is not categorized
    "timestamp": null              # If ingestion time not recorded
}

# NEVER null (RAG will fail if missing):
{
    "source_doc": "...",           # ALWAYS present
    "source_type": "...",          # ALWAYS present (pdf/kaggle/huggingface)
    "section_title": "...",        # ALWAYS present (at least "Uncategorized")
    "chunk_index": 0,              # ALWAYS present (0-based integer)
    "contradiction_check": true,   # ALWAYS true (false chunks excluded)
    "duplicate_check": true        # ALWAYS true (duplicate chunks excluded)
}
```

---

## Citation Format

### HR Pipeline → RAG Service

Metadata fields are used to generate citations:

```python
# From retrieved chunk metadata
citation = {
    "document_name": metadata["source_doc"],      # "hr_policy.pdf"
    "excerpt": chunk_text[:200],                  # First 200 chars
    "page_number": metadata["page_number"],       # 5 (may be null)
    "section": metadata["section_title"],         # "Vacation Policy"
    "chunk_id": chunk_id                          # "chunk_pdf_hash_0"
}

# Rendered in answer
answer_text = f"... personnel are entitled to 20 days of leave [{metadata['source_doc']}, {metadata['section_title']}]."
# Output: "... personnel are entitled to 20 days of leave [hr_policy.pdf, Vacation Policy]."
```

---

## Ingestion Workflow

### HR Pipeline Guarantees

**Before adding chunks to ChromaDB, HR Pipeline MUST**:

1. ✅ Extract text from source documents
2. ✅ Apply contradiction detection (FR-006)
   - Run semantic analysis comparing to PDF policies
   - EXCLUDE any contradictory chunks
3. ✅ Apply duplicate detection (FR-007)
   - Compare new chunks against existing PDF chunks
   - EXCLUDE duplicates (similarity >0.85)
4. ✅ Generate embeddings using `all-MiniLM-L6-v2`
5. ✅ Attach all required metadata fields
6. ✅ Insert into ChromaDB collection `corporate_documents`
7. ✅ Log ingestion event (source, chunk count, validation results)
8. ✅ Update manifest file with checksums and timestamps

**What RAG Service can assume**:
- All chunks in ChromaDB have passed validation
- `contradiction_check` and `duplicate_check` are always `true`
- `embedding_model` is always `"all-MiniLM-L6-v2"`
- Metadata fields are well-formed and non-null (except specified exceptions)

---

## Error Handling

### HR Pipeline Failures → RAG Service Impact

| HR Pipeline Error | Effect on RAG | Recovery |
|------------------|---------------|----------|
| ChromaDB unavailable | RAG cannot retrieve chunks | Contact data engineer |
| Corrupted embeddings | Retrieval fails or returns wrong results | Rebuild vector DB |
| Missing metadata fields | Citations incomplete or missing | Re-ingest documents |
| Wrong embedding model | Vectors incompatible (dimension mismatch) | **CRITICAL**: Rebuild DB with correct model |

### RAG Service Failures → HR Pipeline Impact

| RAG Service Error | Effect on HR Pipeline | Recovery |
|-----------------|----------------------|----------|
| Cannot connect to ChromaDB | Cannot query results | Fix RAG service connectivity |
| Low confidence answers | May indicate data quality issue | Review HR pipeline validation |
| Hallucinated citations | Should not occur if validation passed | Debug prompt engineering |

---

## Version History

| Version | Date | Changes | Approved By |
|---------|------|---------|-------------|
| 1.0 | 2026-01-21 | Initial contract: all-MiniLM-L6-v2, 384-dim embeddings, metadata schema | Data & RAG teams |

---

## Change Request Process

To modify this contract:

1. **Propose** change in Jira issue (link both features)
2. **Review** with both HR Pipeline and RAG Service teams
3. **Test** changes in isolated environment
4. **Align** on timing (may require simultaneous deployment)
5. **Update** version number and date in this document
6. **Deploy** to production with both teams coordinating

**Example**: Changing embedding model requires:
- Rebuild entire ChromaDB (6+ hours for large databases)
- Update RAG service code to accept new dimension
- Re-test all integration tests
- Plan maintenance window

---

## Integration Testing Checklist

✅ **Before handoff from HR Pipeline to RAG Service, verify**:

- [ ] ChromaDB contains at least 100 chunks from PDF
- [ ] All chunks have `embedding_model: "all-MiniLM-L6-v2"`
- [ ] All embeddings are exactly 384 dimensions
- [ ] No metadata fields are null (except allowed exceptions)
- [ ] Sample query retrieves semantically relevant chunks
- [ ] Citation metadata is complete (source_doc, page_number, section_title)
- [ ] Manifest.json records ingestion statistics (chunk count, validation results)
- [ ] Checksums verify data integrity

✅ **RAG Service verifies**:

- [ ] Can connect to ChromaDB API
- [ ] Can generate embedding vectors (384-dim) compatible with stored embeddings
- [ ] Retrieval queries return results within 500ms
- [ ] Citations render correctly from metadata
- [ ] Confidence scores are calculated properly (0.0-1.0)
- [ ] "I don't know" responses trigger at confidence <0.5
- [ ] Sample queries produce expected answers with citations

---

## Support & Questions

**Data Model Questions**: See [data-model.md](../data-model.md)  
**RAG Service Integration**: See [service-interface.md](../service-interface.md)  
**HR Pipeline Spec**: See [1-hr-data-pipeline/spec.md](../../1-hr-data-pipeline/spec.md)

**Contact**:
- **HR Data Pipeline**: Data Engineer (Feature lead: `1-hr-data-pipeline`)
- **RAG LLM Service**: RAG Engineer (Feature lead: `001-rag-pipeline-llm-service`)
