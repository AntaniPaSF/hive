# RAG LLM Service - Environment Configuration
# Copy this file to .env and configure for your environment

# ==================================
# Ollama Configuration
# ==================================
# URL for Ollama API (local or containerized)
OLLAMA_HOST=http://localhost:11434

# Ollama model to use for generation
# Options: mistral:7b, llama3, codellama, etc.
OLLAMA_MODEL=mistral:7b

# ==================================
# Vector Store Configuration
# ==================================
# ChromaDB vector store URL (managed by HR Data Pipeline)
VECTOR_STORE_URL=http://localhost:8001

# Collection name in ChromaDB containing document embeddings
VECTOR_STORE_COLLECTION=hr_documents

# Number of chunks to retrieve per query (top-k)
MAX_RETRIEVED_CHUNKS=5

# ==================================
# Embedding Configuration
# ==================================
# HR Data Pipeline embedding API endpoint
# Provides 384-dim all-MiniLM-L6-v2 embeddings
EMBEDDING_API_URL=http://localhost:8002/embed

# Embedding model name (for validation/logging)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Expected embedding dimension (384 for all-MiniLM-L6-v2)
EMBEDDING_DIMENSION=384

# ==================================
# RAG Service Configuration
# ==================================
# Minimum confidence threshold for returning answers
# Queries with avg similarity < threshold return "I don't know"
MIN_CONFIDENCE_THRESHOLD=0.5

# Service port
RAG_SERVICE_PORT=8000

# ==================================
# Logging Configuration
# ==================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log output format: json, text
LOG_FORMAT=json

# Log file path (leave empty for stdout only)
LOG_FILE=

# ==================================
# API Configuration
# ==================================
# Enable CORS (for FastAPI wrapper integration)
ENABLE_CORS=true

# Allowed CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# ==================================
# Timeout Configuration
# ==================================
# Ollama generation timeout (seconds)
OLLAMA_TIMEOUT=30

# Vector store query timeout (seconds)
VECTOR_STORE_TIMEOUT=10

# Embedding API timeout (seconds)
EMBEDDING_API_TIMEOUT=5

# ==================================
# Retry Configuration
# ==================================
# Max retries for failed API calls
MAX_RETRIES=3

# Retry backoff multiplier (exponential backoff)
RETRY_BACKOFF=2
